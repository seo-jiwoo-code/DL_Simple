{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of model codes \n",
    "# Resnet18, Resnet 50, DenseNet 121, Inception V3, VGG16 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of model codes \n",
    "# Resnet18, Resnet 50, DenseNet 121, Inception V3, VGG16 \n",
    "\n",
    "# from keras.applications import VGG16\n",
    "# from keras.layers import Dense, GlobalAveragePooling2D\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "# # Load the VGG16 model without the fully connected layers\n",
    "# base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# # Freeze the base layers\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# # Add a global average pooling layer to reduce the feature space\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# # Add a dense layer with 100 nodes and a ReLU activation function\n",
    "# x = Dense(100, activation='relu')(x)\n",
    "\n",
    "# # Add the final dense layer with the number of classes in your dataset\n",
    "# predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# # Build the model and compile it\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-macosx_10_14_x86_64.whl (244.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from tensorflow) (1.24.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp39-cp39-macosx_10_14_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m976.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: setuptools in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-macosx_10_9_x86_64.whl (25.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp39-cp39-macosx_10_9_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-macosx_10_9_x86_64.whl (980 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m980.5/980.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-macosx_10_9_x86_64.whl (35 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.51.1-cp39-cp39-macosx_10_10_x86_64.whl (4.6 MB)\n",
      "Requirement already satisfied: packaging in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.0.1-cp39-cp39-macosx_10_9_x86_64.whl (124 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp39-cp39-macosx_10_9_x86_64.whl (13 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/seojiwoo/opt/anaconda3/envs/MerckProject/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.13.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, charset-normalizer, wrapt, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, MarkupSafe, keras, idna, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, werkzeug, requests, markdown, google-auth, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 charset-normalizer-3.0.1 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.8.0 idna-3.4 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 termcolor-2.2.0 urllib3-1.26.14 werkzeug-2.2.2 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# load the data into a pandas DataFrame\n",
    "data = pd.read_csv('image_data.csv')\n",
    "\n",
    "# extract the file paths and quality control labels\n",
    "file_paths = data['filepath'].tolist()\n",
    "labels = data['QC'].tolist()\n",
    "\n",
    "# preprocess the images\n",
    "images = []\n",
    "for file_path in file_paths:\n",
    "    # load the image\n",
    "    image = cv2.imread(file_path)\n",
    "\n",
    "    # preprocess the image (e.g., resize, normalize, etc.)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image.astype('float32') / 255.0\n",
    "\n",
    "    images.append(image)\n",
    "\n",
    "# convert the list of images to a numpy array\n",
    "images = np.array(images)\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Krish.Naik\n",
    "\"\"\"\n",
    "\n",
    "#for the standard VGG16 model, last layer has thousands of outputs. we will cut off the last layer and taylor to our needs. (e.g. QC 1-3, then just need 3 output)\n",
    "from keras.layers import Input, Lambda, Dense, Flatten #for the output layers\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16 #can be applied for other classification models under keras. \n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image #what is this \n",
    "from keras.preprocessing.image import ImageDataGenerator #image augmentation (need to specify?)\n",
    "from keras.models import Sequential #sequential (VGG16)\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224] #inherent design of VGG16 \n",
    "\n",
    "train_path = 'Datasets/Train'\n",
    "valid_path = 'Datasets/Test'\n",
    "\n",
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "#initializes VGG16. adding 3 channels (if it is RGB, it will be 3 channels. if it is b&w it is just 1). don't include the top. \n",
    "\n",
    "# don't train existing weights (it's already trained. bro this is a state-of-art algorithm already)\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False #else a lot of GPU power is required.  \n",
    "  \n",
    "\n",
    "  \n",
    "  # useful for getting number of classes\n",
    "folders = glob('Datasets/Train/*') #how many datasets are present in Datasets/Train? \n",
    "  \n",
    "\n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(vgg.output) #flatten the last layer \n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x) #appending the folders, with a dense layer, with softmax activation\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction) \n",
    "\n",
    "# view the structure of the model\n",
    "model.summary() \n",
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#these are information regarding the data augmentation  \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Datasets/Train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Datasets/Test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "'''r=model.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 5,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)'''\n",
    "\n",
    "# fit the model\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n",
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['acc'], label='train acc')\n",
    "plt.plot(r.history['val_acc'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('facefeatures_new_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing VGG16 can be done in several ways:\n",
    "\n",
    "Fine-tuning the model: Fine-tuning involves training the base model further with a smaller learning rate and a lower number of epochs to avoid overfitting.\n",
    "\n",
    "Changing the optimizer: Different optimizers have different ways of updating the model parameters. Experimenting with different optimizers can improve the model's performance.\n",
    "\n",
    "Hyperparameter tuning: Hyperparameters are parameters that are not learned from the data but are set by the user. Hyperparameters such as the learning rate, the number of hidden layers, and the number of nodes in each layer can be optimized to improve the model's performance.\n",
    "\n",
    "Augmenting the data: Data augmentation is the process of generating new training samples from the existing training data by applying transformations such as rotation, flipping, and scaling. This can increase the amount of training data and improve the model's generalization ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other references i can look at: https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DL (for feature extraction) + ML (for classification) https://www.youtube.com/watch?v=9GzfUzJeyi0&ab_channel=DigitalSreeni \n",
    "\n",
    "# https://youtu.be/9GzfUzJeyi0\n",
    "\n",
    "\"\"\"\n",
    "@author: Sreenivas Bhattiprolu\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(os.listdir(\"images/natural/\"))\n",
    "\n",
    "SIZE = 128\n",
    "\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "for directory_path in glob.glob(\"images/natural/train/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        print(img_path)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "        \n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "\n",
    "# test\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "for directory_path in glob.glob(\"images/natural/validation/*\"):\n",
    "    fruit_label = directory_path.split(\"\\\\\")[-1]\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(fruit_label)\n",
    "        \n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "#Encode labels from text to integers.\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "\n",
    "###################################################################\n",
    "# Normalize pixel values to between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#One hot encode y values for neural network. \n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "#############################\n",
    "\n",
    "activation = 'sigmoid'\n",
    "\n",
    "feature_extractor = Sequential()\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (SIZE, SIZE, 3)))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Flatten())\n",
    "\n",
    "#Add layers for deep learning prediction\n",
    "x = feature_extractor.output  \n",
    "x = Dense(128, activation = activation, kernel_initializer = 'he_uniform')(x)\n",
    "prediction_layer = Dense(4, activation = 'softmax')(x)\n",
    "\n",
    "# Make a new model combining both feature extractor and x\n",
    "cnn_model = Model(inputs=feature_extractor.input, outputs=prediction_layer)\n",
    "cnn_model.compile(optimizer='rmsprop',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "print(cnn_model.summary()) \n",
    "\n",
    "##########################################\n",
    "#Train the CNN model\n",
    "history = cnn_model.fit(x_train, y_train_one_hot, epochs=50, validation_data = (x_test, y_test_one_hot))\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "prediction_NN = cnn_model.predict(x_test)\n",
    "prediction_NN = np.argmax(prediction_NN, axis=-1)\n",
    "prediction_NN = le.inverse_transform(prediction_NN)\n",
    "\n",
    "#Confusion Matrix - verify accuracy of each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(test_labels, prediction_NN)\n",
    "print(cm)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "#Check results on a few select images\n",
    "\n",
    "#n=5 dog park. NN not as good as RF.\n",
    "n=9  #Select the index of image to be loaded for testing\n",
    "img = x_test[n]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "prediction = np.argmax(cnn_model.predict(input_img))  #argmax to convert categorical back to original\n",
    "prediction = le.inverse_transform([prediction])  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction)\n",
    "print(\"The actual label for this image is: \", test_labels[n])\n",
    "\n",
    "################################\n",
    "#Now, let us use features from convolutional network for RF\n",
    "X_for_RF = feature_extractor.predict(x_train) #This is out X input to RF\n",
    "\n",
    "#RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature = feature_extractor.predict(x_test)\n",
    "#Now predict using the trained RF model. \n",
    "prediction_RF = RF_model.predict(X_test_feature)\n",
    "#Inverse le transform to get original label back. \n",
    "prediction_RF = le.inverse_transform(prediction_RF)\n",
    "\n",
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(test_labels, prediction_RF))\n",
    "\n",
    "#Confusion Matrix - verify accuracy of each class\n",
    "cm = confusion_matrix(test_labels, prediction_RF)\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "#Check results on a few select images\n",
    "#n=5 #dog park. RF works better than CNN\n",
    "n=9 #Select the index of image to be loaded for testing\n",
    "img = x_test[n]\n",
    "plt.imshow(img)\n",
    "input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)\n",
    "input_img_features=feature_extractor.predict(input_img)\n",
    "prediction_RF = RF_model.predict(input_img_features)[0] \n",
    "prediction_RF = le.inverse_transform([prediction_RF])  #Reverse the label encoder to original name\n",
    "print(\"The prediction for this image is: \", prediction_RF)\n",
    "print(\"The actual label for this image is: \", test_labels[n])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MerckProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3003c511091e6b541c938bedbf61d12e9a8a9693376ee6a53b067e2706a7bd8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
